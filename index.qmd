---
title: "Density ratios to evaluate and improve the utility of synthetic data"
author: "Thom Benjamin Volker <br> [t.b.volker@uu.nl](mailto:t.b.volker@uu.nl)"
format: 
  revealjs:
    slide-number: true
    df-print: kable
    html-math-method: katex
    theme: dark
---

# Imagine you have access to all the data in the world...

::: {.notes}

Imagine you have access to all the data in the world. 
What a privacy disaster would that be...
But also, what a great opportunity to learn about the world!
How many research questions could we answer if we had that much data. 
Unfortunately, or fortunately, we will never get access to all the data in the world, not in the last place because the data cannot be shared openly.

:::

# If real data is no option,

_maybe synthetic data is!_


::: {.notes}

Synthetic data is fake data, simulated data or generated data. 
As opposed to real data, synthetic data is not collected from real people, but generated from a model.
If the model is a good approximation to reality, the synthetic data can be very useful. 
Because the synthetic data do not map back to individuals, it substantially reduces privacy risks.

:::

# Synthetic data

_Fake data, generated data, simulated data, digital twins_

## Potential use-cases of synthetic data

<br>

- Advancing access to private data for research (e.g., in statistical institutes)

- Advancing open science workflows

- Educational materials

- Software / model testing

## Synthetic data generation cycle

1. Create synthetic data with simple models

2. Evaluate the quality of the synthetic data

3. If necessary, add complexity (alter models, transformations, interactions)

4. Iterate between (2.) and (3.) until synthetic data is good enough


# How do we know whether the synthetic data is good enough?

## 

### Intuitively

Can we use the synthetic data for the same purposes as we wanted to use the real data?

Do the observed and synthetic data have similar distributions?

<br>


### Practically

Do the observed and synthetic data produce similar results under the same analysis?

Can we distinguish between the observed and synthetic data?

# Density ratios for utility^[See _Masashi, Suzuki & Kanamori (2012). Density ratio estimation in machine learning._]

<br>
<br>

$$r(x) = \frac{p(\boldsymbol{X}_{\text{syn }})}{p(\boldsymbol{X}_{\text{obs}})}$$
<br>
<br>
<br>
<br>

::: {.notes}

We propose that density ratios are very suitable for this task. 
Density ratio estimation is a set of techniques developed in machine learning to estimate the ratio of two probability density functions.
The density ratio can be used for various tasks, as broad as change-point detection, prediction and two-sample testing. 
But it is also very useful for evaluating the utility of synthetic data.
That is, if the observed and synthetic data have similar density over the entire multivariate space, then any analysis will yield similar results. 
So, this means that if the density ratio is close to one at every point in the multivariate space, then the synthetic data is good enough. 
If the density ratio is far from one in some subspace of the data, we have to improve the synthetic data in that subspace.
Importantly, the density ratio is estimated directly, rather than estimating the two probability density functions separately and then taking their ratio to improve estimation accuracy. 

:::

## Density ratios for utility evaluation

<!-- $$r(x) = \frac{p(\boldsymbol{X}_{\text{syn }})}{p(\boldsymbol{X}_{obs})}$$ -->

```{r}
#| fig-align: center
library(patchwork)
library(ggplot2)



dlaplace <- function(x, mu = 0, sd = 1) exp(-abs(x-mu)/(sd / sqrt(2))) / (2*(sd / sqrt(2)))
dratio_lap_norm <- function(x, mu = 0, sd = 1) {
  dnorm(x, mu, sd) / dlaplace(x, mu, sd)
}

ggplot() +
  stat_function(fun = dlaplace, args = list(mu = 0, sd = 1),
                col = "#FDAE61", linewidth = 1, linetype = 1) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1),
                col = "#F46D43", linewidth = 1, linetype = 4) +
  xlim(-5, 5) +
  ylim(0, 0.8) +
  ggdark::dark_mode() +
  ylab(NULL) +
ggplot() +
  stat_function(fun = dratio_lap_norm, args = list(mu = 0, sd = 1),
                linewidth = 1, linetype = 1, col = "#FEE08B") +
  xlim(-5, 5) +
  ylim(0, 2) +
  ggdark::dark_mode() +
  ylab(NULL) +
ggplot() +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1),
                col = "#FDAE61", linewidth = 1, linetype = 1) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1),
                col = "#F46D43", linewidth = 1, linetype = 4) +
  xlim(-5, 5) +
  ylim(0, 0.8) +
  ggdark::dark_mode() +
  ylab(NULL) +
ggplot() +
  geom_abline(intercept = 1, slope = 0, linewidth = 1, linetype = 1,
              col = "#FEE08B") +
  ggdark::dark_mode() +
  xlim(-5, 5) +
  ylim(0, 2) +
  ylab(NULL)
```
## Density ratios in practice

1. Estimate the density ratio directly and non-parametrically

- Implemented in `R`-package [`densityratio`](https://github.com/thomvolker/densityratio)

2. Calculate a discrepancy measure for the synthetic data

- Kullback-Leibler divergence; Pearson divergence

3. Compare discrepancy measures for different data sets

4. Optionally: Test the null hypothesis $p(\boldsymbol{X}_{\text{syn}}) = p(\boldsymbol{X}_{\text{obs}})$

## Density ratios for synthetic data (multivariate examples) {.smaller}

### U.S. Current Population Survey (n = 5000)^[Thanks to JÃ¶rg Drechsler for sharing the data.]

- Four continuous variables (_age, income, social security payments, household taxes_)
- Four categorical variables (_sex, race, marital status, educational attainment_)

### Synthetic data models

(Multinomial) logistic regression for categorical variables

1. Linear regression
2. Linear regression with transformations (cubic root)
3. Linear regression with transformations and semi-continuous modelling

## Utility of the synthetic data

![](files/syn-PEs.png)

## Reweighting synthetic data: regression coefficients

```{r}
library(tibble)
library(densityratio)
library(patchwork)

set.seed(23)
N <- 1000
obs <- tibble(
  x = rnorm(N, 0, 1),
  y = 0.5*x+rnorm(N,0,sqrt(3/4))
)
syn <- tibble(
  x = rnorm(N, 0, 1),
  y = rnorm(N, 0, 1)
)

fit <- ulsif(obs, syn, lambda = 0.0001)
w   <- predict(fit, syn)

ggplot(obs) +
  geom_point(aes(x, y), alpha = 0.4) +
  ggdark::dark_mode() +
  ggtitle("Original data") +
ggplot(syn) +
  geom_point(aes(x, y, col = w), alpha = 0.5) +
  scale_color_viridis_c(begin = 0.7, end = 0.7, option = "F") +
  ggdark::dark_mode() +
  theme(legend.position = "none") +
  ggtitle("Synthetic data")
```

## Reweighting synthetic data: regression coefficients

```{r}
ggplot(obs) +
  geom_point(aes(x, y), alpha = 0.4) +
  ggdark::dark_mode() +
  ggtitle("Original data") +
ggplot(syn) +
  geom_point(aes(x, y, col = w), alpha = 0.5) +
  scale_color_viridis_c(begin = 0.3, end = 1, option = "F") +
  ggdark::dark_mode() +
  ggtitle("Synthetic data")
```

## Reweighting synthetic data: regression coefficients


```{r}
fit_obs <- lm(y ~ x, data = obs)
fit_syn <- lm(y ~ x, data = syn)
fit_wgt <- lm(y ~ x, data = syn, weights = pmax(0,w))

matrix(c(coef(fit_obs), coef(fit_syn), coef(fit_wgt)), 2,
       dimnames = list(c("b0", "b1"), c("Observed", "Synthetic", "Reweighted"))) |>
  data.frame()
```
## Other advantages of density ratios for utility

__Use density ratios to discard synthetic outliers__


__High-dimensional extensions__

- Find a $m < p$-dimensional subspace in which the synthetic and observed data are maximally different

- Estimate the density ratio in this subspace


__Automatic cross-validation for hyperparameter selection__

# Thanks for your attention!

_Even if it was simulated..._

<br>

__Questions?__

[t.b.volker@uu.nl](mailto:t.b.volker@uu.nl)
